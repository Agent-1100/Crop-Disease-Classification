{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12209964,"sourceType":"datasetVersion","datasetId":7691760}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.254797Z","iopub.execute_input":"2025-07-27T17:21:15.255564Z","iopub.status.idle":"2025-07-27T17:21:15.259010Z","shell.execute_reply.started":"2025-07-27T17:21:15.255538Z","shell.execute_reply":"2025-07-27T17:21:15.258228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom scipy.signal import wiener\n\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.manifold import TSNE\nfrom umap import UMAP\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.applications import (\n    VGG16, VGG19, ResNet50, InceptionV3, Xception, MobileNetV2, \n    DenseNet121, EfficientNetB0, InceptionResNetV2\n)\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Average\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.metrics import Precision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.260273Z","iopub.execute_input":"2025-07-27T17:21:15.260497Z","iopub.status.idle":"2025-07-27T17:21:15.279513Z","shell.execute_reply.started":"2025-07-27T17:21:15.260476Z","shell.execute_reply":"2025-07-27T17:21:15.278980Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 1. CONFIGURATION AND SETUP ---","metadata":{}},{"cell_type":"markdown","source":"# --- Dataset and Output Paths ---","metadata":{}},{"cell_type":"code","source":"SOURCE_DIR = '/kaggle/input/bone-fracture/bone_fracture_data'\nBASE_DIR = '/kaggle/working/bone_fracture_dataset_final'\nOUTPUT_DIR = '/kaggle/working/model_outputs' # Directory to save all results\n# Data_Selector = ['Peach___', 'Pepper,_bell___', 'Strawberry___']\n\n# CLASS_MAP = {\n#     'Peach___': 'peach',\n#     'Pepper,_bell___': 'bell_pepper',\n#     'Strawberry___': 'strawberry'\n#     # Add other classes here following the same pattern\n# }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.280280Z","iopub.execute_input":"2025-07-27T17:21:15.280954Z","iopub.status.idle":"2025-07-27T17:21:15.302361Z","shell.execute_reply.started":"2025-07-27T17:21:15.280936Z","shell.execute_reply":"2025-07-27T17:21:15.301851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Model and Training Parameters ---","metadata":{}},{"cell_type":"code","source":"IMG_HEIGHT = 224\nIMG_WIDTH = 224\nBATCH_SIZE = 32\nNUM_CLASSES = 1 \nEPOCHS = 30\nEARLY_STOPPING_PATIENCE = 10\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.303708Z","iopub.execute_input":"2025-07-27T17:21:15.303946Z","iopub.status.idle":"2025-07-27T17:21:15.322820Z","shell.execute_reply.started":"2025-07-27T17:21:15.303931Z","shell.execute_reply":"2025-07-27T17:21:15.322270Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Preprocessing Toggles ---","metadata":{}},{"cell_type":"code","source":"APPLY_SEGMENTATION = True\nAPPLY_CLAHE = False\nAPPLY_GAUSSIAN_BLUR = False \nAPPLY_MEDIAN_FILTER = False\nAPPLY_WIENER_FILTER = False\nAPPLY_HISTOGRAM_EQUALIZATION = False\nAPPLY_LAPLACIAN_FILTER = False\nAPPLY_AVERAGE_FILTER = False\nAPPLY_SOBEL_FILTER = False\nAPPLY_CANNY_FILTER = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.323450Z","iopub.execute_input":"2025-07-27T17:21:15.323680Z","iopub.status.idle":"2025-07-27T17:21:15.339687Z","shell.execute_reply.started":"2025-07-27T17:21:15.323644Z","shell.execute_reply":"2025-07-27T17:21:15.339158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_and_merge_directories():\n    \"\"\"\n    Copies a dataset that is already split into train/test/valid folders.\n    It merges any subdirectories found within a class folder (e.g., 'fractured')\n    into a single flat folder in the destination.\n    \"\"\"\n    # Delete the base directory if it exists to ensure a fresh start\n    if os.path.exists(BASE_DIR):\n        print(f\"Directory '{BASE_DIR}' already exists. Deleting it to recreate...\")\n        shutil.rmtree(BASE_DIR)\n\n    print(\"Creating new train/val/test directories...\")\n    # Define and create the new destination directories\n    train_dir_dest = os.path.join(BASE_DIR, 'train')\n    val_dir_dest = os.path.join(BASE_DIR, 'val')\n    test_dir_dest = os.path.join(BASE_DIR, 'test')\n\n    os.makedirs(train_dir_dest)\n    os.makedirs(val_dir_dest)\n    os.makedirs(test_dir_dest)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    try:\n        # Map source splits ('valid') to destination splits ('val')\n        split_map = {\n            'train': train_dir_dest,\n            'test': test_dir_dest,\n            'valid': val_dir_dest\n        }\n\n        for source_split_name, dest_split_path in split_map.items():\n            source_path = os.path.join(SOURCE_DIR, source_split_name)\n\n            if not os.path.exists(source_path):\n                print(f\"WARNING: Source directory not found, skipping: '{source_path}'\")\n                continue\n\n            print(f\"Processing '{source_path}'...\")\n\n            # Get the class directories (e.g., 'fractured', 'normal')\n            class_names = [d for d in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, d))]\n\n            for class_name in class_names:\n                print(f\"  -> Processing class: '{class_name}'\")\n                \n                src_class_dir = os.path.join(source_path, class_name)\n                dest_class_dir = os.path.join(dest_split_path, class_name)\n\n                # Create the destination class subdirectory (e.g., .../train/fractured)\n                os.makedirs(dest_class_dir, exist_ok=True)\n\n                # --- KEY CHANGE: Use os.walk() to find all files in subdirectories ---\n                # This will \"flatten\" the structure by copying all images from any subfolder\n                # into the main destination class directory.\n                file_count = 0\n                for dirpath, _, filenames in os.walk(src_class_dir):\n                    for f in filenames:\n                        # Optional: Filter for image files to avoid copying other file types\n                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n                            src_file_path = os.path.join(dirpath, f)\n                            shutil.copy(src_file_path, dest_class_dir)\n                            file_count += 1\n                \n                print(f\"    -> Copied {file_count} files to '{dest_class_dir}'\")\n\n\n        print(\"\\nData copying, merging, and setup complete.\")\n        print(f\"New flattened dataset is ready at: '{BASE_DIR}'\")\n\n    except FileNotFoundError:\n        print(f\"ERROR: The main source directory was not found at '{SOURCE_DIR}'. Please check the path.\")\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n\n# --- Run the Setup ---\nsetup_and_merge_directories()\n\n# You can now use these variables to point to your newly organized dataset\ntrain_dir = os.path.join(BASE_DIR, 'train')\nval_dir = os.path.join(BASE_DIR, 'val')\ntest_dir = os.path.join(BASE_DIR, 'test')\n\nprint(f\"\\nPaths to new dataset:\")\nprint(f\"Train: {train_dir}\")\nprint(f\"Val:   {val_dir}\")\nprint(f\"Test:  {test_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:15.340246Z","iopub.execute_input":"2025-07-27T17:21:15.340401Z","iopub.status.idle":"2025-07-27T17:21:21.212510Z","shell.execute_reply.started":"2025-07-27T17:21:15.340388Z","shell.execute_reply":"2025-07-27T17:21:21.211705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 2. PREPROCESSING FUNCTIONS ---","metadata":{}},{"cell_type":"code","source":"def apply_segmentation(image):\n\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)    \n    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n    return segmented_image\n\ndef apply_clahe(image):\n    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab_image)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    cl = clahe.apply(l)\n    merged_channels = cv2.merge([cl, a, b])\n    return cv2.cvtColor(merged_channels, cv2.COLOR_LAB2RGB)\n\ndef apply_gaussian_blur(image):\n    return cv2.GaussianBlur(image, (5, 5), 0)\n\ndef apply_median_blur(image):\n    return cv2.medianBlur(image, 5)\n\ndef apply_wiener_filter(image):\n    img_float = image.astype(np.float64) / 255.0\n    filtered_channels = [wiener(channel) for channel in cv2.split(img_float)]\n    filtered_image = cv2.merge(filtered_channels)\n    return (np.clip(filtered_image, 0, 1) * 255).astype(np.uint8)\n\ndef apply_histogram_equalization(image):\n    img_ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n    img_ycrcb[:, :, 0] = cv2.equalizeHist(img_ycrcb[:, :, 0])\n    return cv2.cvtColor(img_ycrcb, cv2.COLOR_YCrCb2RGB)\n\ndef apply_laplacian_filter(image):\n    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n    abs_laplacian = np.absolute(laplacian)\n    return np.uint8(abs_laplacian)\n\ndef apply_average_filter(image):\n    return cv2.blur(image, (5, 5))\n\ndef apply_sobel_filter(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n    sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n    sobel_norm = cv2.normalize(sobel_combined, None, 0, 255, cv2.NORM_MINMAX)\n    sobel_uint8 = np.uint8(sobel_norm)\n    return cv2.cvtColor(sobel_uint8, cv2.COLOR_GRAY2RGB)\n\ndef apply_canny_filter(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    edges = cv2.Canny(gray, threshold1=100, threshold2=200)\n    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n\ndef get_preprocessing_function(model_specific_preprocess_input):\n    def master_preprocessing_function(image):\n        if model_specific_preprocess_input is None:\n            return image / 255.0\n            \n        processed_image = image.astype('uint8')\n        if APPLY_SEGMENTATION: processed_image = apply_segmentation(processed_image)\n        if APPLY_WIENER_FILTER: processed_image = apply_wiener_filter(processed_image)\n        if APPLY_MEDIAN_FILTER: processed_image = apply_median_blur(processed_image)\n        if APPLY_AVERAGE_FILTER: processed_image = apply_average_filter(processed_image)\n        if APPLY_GAUSSIAN_BLUR: processed_image = apply_gaussian_blur(processed_image)\n        if APPLY_CLAHE: processed_image = apply_clahe(processed_image)\n        if APPLY_HISTOGRAM_EQUALIZATION: processed_image = apply_histogram_equalization(processed_image)\n        if APPLY_LAPLACIAN_FILTER: processed_image = apply_laplacian_filter(processed_image)\n        if APPLY_SOBEL_FILTER: processed_image = apply_sobel_filter(processed_image)\n        if APPLY_CANNY_FILTER: processed_image = apply_canny_filter(processed_image)\n        processed_image = processed_image.astype('float32')\n        return model_specific_preprocess_input(processed_image)\n    return master_preprocessing_function","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:21.214273Z","iopub.execute_input":"2025-07-27T17:21:21.214489Z","iopub.status.idle":"2025-07-27T17:21:21.226161Z","shell.execute_reply.started":"2025-07-27T17:21:21.214472Z","shell.execute_reply":"2025-07-27T17:21:21.225598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Function to Create the Custom CNN Model ---","metadata":{}},{"cell_type":"code","source":"def create_custom_cnn(input_shape, num_classes):\n    \"\"\"Builds and returns the user-defined custom CNN model.\"\"\"\n    model = keras.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Conv2D(16, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(32, (1, 1), activation='relu'),\n        layers.Conv2D(32, (3, 3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(64, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (5, 5), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(16, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(16, (5, 5), activation='relu'),\n        layers.BatchNormalization(),\n        # Add a feature extractor layer name for Grad-CAM and feature projection\n        layers.GlobalAveragePooling2D(name='feature_extractor_layer'),\n        layers.Dense(num_classes, activation='sigmoid')\n    ])\n    print(\"--- Custom CNN Model Summary ---\")\n    model.summary()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:21.226779Z","iopub.execute_input":"2025-07-27T17:21:21.227011Z","iopub.status.idle":"2025-07-27T17:21:21.249154Z","shell.execute_reply.started":"2025-07-27T17:21:21.226995Z","shell.execute_reply":"2025-07-27T17:21:21.248592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 3. VISUALIZATION AND REPORTING FUNCTIONS ---","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history, model_name, save_dir):\n    \"\"\"Plots accuracy, loss, and precision from the model's history.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n    metrics = ['accuracy', 'loss', 'precision']\n    for i, metric in enumerate(metrics):\n        val_metric = f'val_{metric}'\n        axes[i].plot(history.history[metric], label=f'Train {metric.capitalize()}')\n        axes[i].plot(history.history[val_metric], label=f'Validation {metric.capitalize()}')\n        axes[i].set_title(f'{model_name} - {metric.capitalize()}')\n        axes[i].legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_training_history.png'))\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, model_name, save_dir):\n    \"\"\"Plots a confusion matrix.\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'{model_name} - Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.savefig(os.path.join(save_dir, f'{model_name}_confusion_matrix.png'))\n    plt.show()\n\ndef plot_roc_pr_curves(y_true, y_pred_prob, model_name, save_dir):\n    \"\"\"Plots ROC and Precision-Recall curves, simplified for binary classification.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # ROC Curve\n    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n    roc_auc = auc(fpr, tpr)\n    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    axes[0].set_title(f'{model_name} - ROC Curve'); axes[0].legend(loc=\"lower right\")\n\n    # Precision-Recall Curve\n    precision, recall, _ = precision_recall_curve(y_true, y_pred_prob)\n    pr_auc = auc(recall, precision)\n    axes[1].plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {pr_auc:.2f})')\n    axes[1].set_title(f'{model_name} - Precision-Recall Curve'); axes[1].legend(loc=\"lower left\")\n\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_roc_pr_curves.png'))\n    plt.show()\n\ndef plot_projections(features, labels, class_names, model_name, save_dir):\n    \"\"\"Plots t-SNE and UMAP projections of features.\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n    \n    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)-1)).fit_transform(features)\n    df_tsne = pd.DataFrame({'x': tsne[:, 0], 'y': tsne[:, 1], 'label': [class_names[l] for l in labels]})\n    sns.scatterplot(data=df_tsne, x='x', y='y', hue='label', ax=axes[0], palette='viridis').set_title(f'{model_name} - t-SNE')\n    \n    umap_proj = UMAP(n_neighbors=15, min_dist=0.1, random_state=42).fit_transform(features)\n    df_umap = pd.DataFrame({'x': umap_proj[:, 0], 'y': umap_proj[:, 1], 'label': [class_names[l] for l in labels]})\n    sns.scatterplot(data=df_umap, x='x', y='y', hue='label', ax=axes[1], palette='viridis').set_title(f'{model_name} - UMAP')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_projections.png'))\n    plt.show()\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n    \"\"\"Creates a Grad-CAM heatmap.\"\"\"\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        # For binary with sigmoid, the class channel is the output itself.\n        class_channel = preds\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef save_and_display_gradcam(img_path, heatmap, cam_path, alpha=0.4):\n    \"\"\"Saves a superimposed Grad-CAM image.\"\"\"\n    img = cv2.imread(img_path); img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])); heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = np.clip(heatmap * alpha + img, 0, 255).astype('uint8')\n    cv2.imwrite(cam_path, superimposed_img)\n\ndef visualize_class_maps(model, last_conv_layer_name, preprocessor, model_name, save_dir, test_dir_path):\n    \"\"\"Displays Grad-CAM for one sample from each class in a 1xN layout.\"\"\"\n    class_names = sorted(os.listdir(test_dir_path))\n    plt.figure(figsize=(12, 6))\n    for i, class_name in enumerate(class_names):\n        img_path = os.path.join(test_dir_path, class_name, os.listdir(os.path.join(test_dir_path, class_name))[0])\n        img_array = img_to_array(load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH)))\n        img_preprocessed = preprocessor(img_array.copy()) if preprocessor else img_array / 255.0\n        img_for_model = np.expand_dims(img_preprocessed, axis=0)\n        heatmap = make_gradcam_heatmap(img_for_model, model, last_conv_layer_name)\n        cam_path = os.path.join(save_dir, f'{model_name}_gradcam_{class_name}.png')\n        save_and_display_gradcam(img_path, heatmap, cam_path)\n        ax = plt.subplot(1, len(class_names), i + 1)\n        ax.imshow(cv2.cvtColor(cv2.imread(cam_path), cv2.COLOR_BGR2RGB)); ax.set_title(f'Grad-CAM: {class_name}'); ax.axis(\"off\")\n    plt.tight_layout(); plt.show()\n\ndef visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, save_dir, num_examples_per_class=2):\n    \"\"\"Shows sample predictions, highlighting correct and incorrect ones.\"\"\"\n    filenames = test_generator.filenames\n    examples_shown = {name: 0 for name in class_names}\n    fig, axes = plt.subplots(nrows=num_examples_per_class, ncols=len(class_names), figsize=(18, 5 * num_examples_per_class), squeeze=False)\n    fig.suptitle(f'{model_name} - Prediction Samples', fontsize=20)\n    for i in range(len(filenames)):\n        if all(v >= num_examples_per_class for v in examples_shown.values()): break\n        true_label_idx = y_true[i]\n        true_label_name = class_names[true_label_idx]\n        if examples_shown[true_label_name] < num_examples_per_class:\n            img_path = os.path.join(test_generator.directory, filenames[i])\n            ax = axes[examples_shown[true_label_name], true_label_idx]\n            ax.imshow(load_img(img_path))\n            ax.axis('off')\n            title_color = 'green' if y_pred[i] == true_label_idx else 'red'\n            ax.set_title(f\"True: {true_label_name}\\nPred: {class_names[y_pred[i]]}\", color=title_color)\n            examples_shown[true_label_name] += 1\n    fig.tight_layout(rect=[0, 0, 1, 0.96]); plt.savefig(os.path.join(save_dir, f'{model_name}_prediction_samples.png')); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:21:21.249948Z","iopub.execute_input":"2025-07-27T17:21:21.250116Z","iopub.status.idle":"2025-07-27T17:21:21.273067Z","shell.execute_reply.started":"2025-07-27T17:21:21.250103Z","shell.execute_reply":"2025-07-27T17:21:21.272517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 4. MAIN TRAINING & EVALUATION LOOP ---","metadata":{}},{"cell_type":"markdown","source":" # --- Evaluation & Visualization ---","metadata":{}},{"cell_type":"code","source":"# --- Model Registry ---\nMODELS = {\n    'CustomCNN': (None, None),\n    'VGG16': (VGG16, tf.keras.applications.vgg16.preprocess_input),\n    'VGG19': (VGG19, tf.keras.applications.vgg19.preprocess_input),\n    'ResNet50': (ResNet50, tf.keras.applications.resnet50.preprocess_input),\n    'InceptionV3': (InceptionV3, tf.keras.applications.inception_v3.preprocess_input),\n    'Xception': (Xception, tf.keras.applications.xception.preprocess_input),\n    'MobileNetV2': (MobileNetV2, tf.keras.applications.mobilenet_v2.preprocess_input),\n    'DenseNet121': (DenseNet121, tf.keras.applications.densenet.preprocess_input),\n    'EfficientNetB0': (EfficientNetB0, tf.keras.applications.efficientnet.preprocess_input),\n    'InceptionResNetV2': (InceptionResNetV2, tf.keras.applications.inception_resnet_v2.preprocess_input),\n}\n\n# Main Training and Evaluation Loop\nfor model_name, (model_constructor, preprocess_input) in MODELS.items():\n    print(f\"\\n{'='*25} Training and Evaluating: {model_name} {'='*25}\")\n    model_save_dir = os.path.join(OUTPUT_DIR, model_name)\n    os.makedirs(model_save_dir, exist_ok=True)\n    \n    # Data Generators\n    if model_name == 'CustomCNN':\n        train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n        val_test_datagen = ImageDataGenerator(rescale=1./255)\n    else:\n        train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n        val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n    validation_generator = val_test_datagen.flow_from_directory(val_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n    test_generator = val_test_datagen.flow_from_directory(test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n    \n    # Model Building\n    if model_name == 'CustomCNN':\n        model = create_custom_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=NUM_CLASSES)\n    else:\n        base_model = model_constructor(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n        base_model.trainable = False\n        x = GlobalAveragePooling2D(name='feature_extractor_layer')(base_model.output)\n        x = Dense(128, activation='relu')(x)\n        x = Dropout(0.5)(x)\n        predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)\n        model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # Model Training\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy', Precision(name='precision')])\n    best_model_path = os.path.join(model_save_dir, f'{model_name}_best.keras')\n    callbacks = [\n        EarlyStopping(monitor='val_accuracy', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True),\n        ModelCheckpoint(filepath=best_model_path, save_best_only=True, monitor='val_accuracy')\n    ]\n    history = model.fit(train_generator, epochs=EPOCHS, validation_data=validation_generator, callbacks=callbacks)\n    \n    # Evaluation & Visualization\n    print(f\"\\n--- Loading best model from '{best_model_path}' for evaluation ---\")\n    model = tf.keras.models.load_model(best_model_path)\n    \n    plot_training_history(history, model_name, model_save_dir)\n    \n    y_pred_prob = model.predict(test_generator).flatten()\n    y_pred = (y_pred_prob > 0.5).astype(int)\n    y_true = test_generator.classes\n    class_names = list(test_generator.class_indices.keys())\n    \n    print(f'\\nClassification Report for {model_name}:\\n{classification_report(y_true, y_pred, target_names=class_names)}')\n    plot_confusion_matrix(y_true, y_pred, class_names, model_name, model_save_dir)\n    plot_roc_pr_curves(y_true, y_pred_prob, model_name, model_save_dir)\n    \n    # Feature Projection Visualization\n    feature_extractor = Model(inputs=model.inputs, outputs=model.get_layer('feature_extractor_layer').output)\n    test_features = feature_extractor.predict(test_generator)\n    plot_projections(test_features, y_true, class_names, model_name, model_save_dir)\n    \n    # --- KEY CHANGE: Grad-CAM Visualization Skipped for CustomCNN ---\n    last_conv_layer_name = next((layer.name for layer in reversed(model.layers) if 'conv' in layer.name.lower()), None)\n    \n    # Only run Grad-CAM if a conv layer is found AND the model is NOT the CustomCNN\n    if last_conv_layer_name and model_name != 'CustomCNN':\n        print(f\"Generating Grad-CAM for {model_name} using layer: {last_conv_layer_name}\")\n        preprocessor = preprocess_input\n        visualize_class_maps(model, last_conv_layer_name, preprocessor, model_name, model_save_dir, test_dir)\n    else:\n        # This will now be triggered for CustomCNN or if no conv layer is found\n        print(f\"Skipping Grad-CAM visualization for {model_name}.\")\n    \n    # Prediction Visualization\n    visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, model_save_dir)\n\n    print(f\"\\nFinished processing {model_name}. Results saved to {model_save_dir}\")\n\nprint(\"\\nAll models have been trained and evaluated.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:25:25.820419Z","iopub.execute_input":"2025-07-27T17:25:25.820748Z","execution_failed":"2025-07-27T17:29:43.917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_ensemble(ensemble_model_names, ensemble_name):\n    \"\"\"\n    Loads a list of binary classification models, averages their predictions, \n    and evaluates the resulting ensemble.\n    \"\"\"\n    print(f\"\\n{'='*20} Creating and Evaluating Ensemble: {ensemble_name} {'='*20}\")\n    \n    all_preds_prob = []\n    y_true_ensemble = None\n    class_names_ensemble = None\n\n    for model_name in ensemble_model_names:\n        print(f\"--- Loading model: {model_name} for ensembling ---\")\n        \n        # Get the preprocessing function from the MODELS dictionary\n        _ , preprocess_input = MODELS.get(model_name, (None, None))\n        \n        model_path = os.path.join(OUTPUT_DIR, model_name, f'{model_name}_best.keras')\n        if not os.path.exists(model_path):\n            print(f\"Warning: Model file not found for {model_name} at {model_path}. Skipping.\")\n            continue\n        \n        model = tf.keras.models.load_model(model_path)\n        \n        # Define the appropriate data generator for the model\n        if model_name == 'CustomCNN':\n             test_datagen = ImageDataGenerator(rescale=1./255)\n        else:\n             test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n        # CHANGE 1: Use `class_mode='binary'` for the generator\n        test_generator_ensemble = test_datagen.flow_from_directory(\n            test_dir, \n            target_size=(IMG_HEIGHT, IMG_WIDTH), \n            batch_size=BATCH_SIZE,\n            class_mode='binary',  # Corrected for binary classification\n            shuffle=False\n        )\n        \n        # Get the ground truth labels and class names only once\n        if y_true_ensemble is None:\n            y_true_ensemble = test_generator_ensemble.classes\n            class_names_ensemble = list(test_generator_ensemble.class_indices.keys())\n            \n        # CHANGE 2: Get predictions and flatten them for binary output\n        # model.predict() will return shape (n_samples, 1), so we flatten it\n        preds_prob = model.predict(test_generator_ensemble).flatten()\n        all_preds_prob.append(preds_prob)\n\n    if len(all_preds_prob) < 2:\n        print(f\"Could not create ensemble '{ensemble_name}' because fewer than 2 valid models were found.\")\n        return\n\n    print(f\"\\n--- Averaging predictions for '{ensemble_name}' ---\")\n    \n    # CHANGE 3: Average probabilities and determine class prediction via threshold\n    ensemble_preds_prob = np.mean(all_preds_prob, axis=0)\n    ensemble_y_pred = (ensemble_preds_prob > 0.5).astype(int) # Use 0.5 threshold\n\n    # Create a directory to save ensemble results\n    ensemble_save_dir = os.path.join(OUTPUT_DIR, ensemble_name.replace(\" \", \"_\").lower())\n    os.makedirs(ensemble_save_dir, exist_ok=True)\n\n    # --- Evaluation ---\n    print(f'\\nClassification Report for {ensemble_name}:\\n{classification_report(y_true_ensemble, ensemble_y_pred, target_names=class_names_ensemble)}')\n    \n    # Plotting functions\n    plot_confusion_matrix(y_true_ensemble, ensemble_y_pred, class_names_ensemble, ensemble_name, ensemble_save_dir)\n    \n    # CHANGE 4: Call plot_roc_pr_curves with the correct 4 arguments\n    plot_roc_pr_curves(y_true_ensemble, ensemble_preds_prob, ensemble_name, ensemble_save_dir)\n    \n    print(f\"\\nFinished processing {ensemble_name}. Results saved to {ensemble_save_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:22:55.733429Z","iopub.status.idle":"2025-07-27T17:22:55.733643Z","shell.execute_reply.started":"2025-07-27T17:22:55.733542Z","shell.execute_reply":"2025-07-27T17:22:55.733551Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Define and run hard-coded ensembles ---","metadata":{}},{"cell_type":"code","source":"# Ensemble of 2 models\nevaluate_ensemble(['VGG16', 'EfficientNetB0'], \"Ensemble of 2 (VGG16, EfficientNetB0)\")\nevaluate_ensemble(['VGG19', 'EfficientNetB0'], \"Ensemble of 2 (VGG19, EfficientNetB0)\")\nevaluate_ensemble(['ResNet50', 'EfficientNetB0'], \"Ensemble of 2 (ResNet50, EfficientNetB0)\")\nevaluate_ensemble(['MobileNetV2', 'EfficientNetB0'], \"Ensemble of 2 (MobileNetV2, EfficientNetB0)\")\nevaluate_ensemble(['ResNet50', 'MobileNetV2'], \"Ensemble of 2 (ResNet50, MobileNetV2)\")\nevaluate_ensemble(['Xception', 'MobileNetV2'], \"Ensemble of 2 (Xception, MobileNetV2)\")\nevaluate_ensemble(['EfficientNetB0', 'Xception'], \"Ensemble of 2 (EfficientNetB0, Xception)\")\nevaluate_ensemble(['DenseNet121', 'EfficientNetB0'], \"Ensemble of 2 (DenseNet121, EfficientNetB0)\")\n\n# Ensemble of 3 models\nevaluate_ensemble(['VGG19', 'EfficientNetB0', 'InceptionV3'], \"Ensemble of 3 (VGG19, EfficientNetB0, InceptionV3)\")\nevaluate_ensemble(['MobileNetV2', 'EfficientNetB0', 'InceptionV3'], \"Ensemble of 3 (MobileNetV2, EfficientNetB0, InceptionV3)\")\nevaluate_ensemble(['DenseNet121', 'EfficientNetB0', 'MobileNetV2'], \"Ensemble of 3 (DenseNet121, EfficientNetB0, MobileNetV2)\")\nevaluate_ensemble(['EfficientNetB0', 'VGG19', 'MobileNetV2'], \"Ensemble of 3 (EfficientNetB0, VGG19, MobileNetV2)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T17:22:55.734236Z","iopub.status.idle":"2025-07-27T17:22:55.734530Z","shell.execute_reply.started":"2025-07-27T17:22:55.734406Z","shell.execute_reply":"2025-07-27T17:22:55.734421Z"}},"outputs":[],"execution_count":null}]}