{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 1. SETUP & CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:37:24.985275Z",
     "iopub.status.busy": "2025-07-20T07:37:24.984568Z",
     "iopub.status.idle": "2025-07-20T07:37:58.662417Z",
     "shell.execute_reply": "2025-07-20T07:37:58.661642Z",
     "shell.execute_reply.started": "2025-07-20T07:37:24.985244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, ResNet50, InceptionV3, Xception, MobileNetV2, \n",
    "    DenseNet121, EfficientNetB0\n",
    ")\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Main Paths and Parameters ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:37:58.664408Z",
     "iopub.status.busy": "2025-07-20T07:37:58.663900Z",
     "iopub.status.idle": "2025-07-20T07:37:58.667771Z",
     "shell.execute_reply": "2025-07-20T07:37:58.667068Z",
     "shell.execute_reply.started": "2025-07-20T07:37:58.664387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SOURCE_DIR = '/kaggle/input/five-crop-diseases-dataset/Crop Diseases Dataset/Crop Diseases/Crop___Disease/Corn'\n",
    "BASE_DIR = '/kaggle/working/corn_dataset_split'\n",
    "OUTPUT_DIR = '/kaggle/working/model_outputs' # Directory to save all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Model & Training Parameters ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:37:58.668821Z",
     "iopub.status.busy": "2025-07-20T07:37:58.668578Z",
     "iopub.status.idle": "2025-07-20T07:37:58.730489Z",
     "shell.execute_reply": "2025-07-20T07:37:58.729928Z",
     "shell.execute_reply.started": "2025-07-20T07:37:58.668799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4 \n",
    "EPOCHS = 50\n",
    "EARLY_STOPPING_PATIENCE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- CUSTOM PRE-PROCESSING CONTROL SWITCHES ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:37:58.731497Z",
     "iopub.status.busy": "2025-07-20T07:37:58.731213Z",
     "iopub.status.idle": "2025-07-20T07:37:58.745190Z",
     "shell.execute_reply": "2025-07-20T07:37:58.744503Z",
     "shell.execute_reply.started": "2025-07-20T07:37:58.731476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "APPLY_CLAHE = False         # Set to True to apply CLAHE for contrast enhancement\n",
    "APPLY_GAUSSIAN_BLUR = False  # Set to True to apply Gaussian Blur to reduce noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 2. DATA SPLITTING & DIRECTORY SETUP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:37:58.746819Z",
     "iopub.status.busy": "2025-07-20T07:37:58.746629Z",
     "iopub.status.idle": "2025-07-20T07:38:16.789759Z",
     "shell.execute_reply": "2025-07-20T07:38:16.789176Z",
     "shell.execute_reply.started": "2025-07-20T07:37:58.746803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_directories():\n",
    "    if os.path.exists(BASE_DIR):\n",
    "        print(f\"Directory '{BASE_DIR}' already exists. Skipping creation.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Creating new train/val/test directories...\")\n",
    "    train_dir = os.path.join(BASE_DIR, 'train')\n",
    "    val_dir = os.path.join(BASE_DIR, 'val')\n",
    "    test_dir = os.path.join(BASE_DIR, 'test')\n",
    "    \n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(val_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        class_names = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "        for class_name in class_names:\n",
    "            cleaned_name = class_name.replace('Corn___', '')\n",
    "            for d in [train_dir, val_dir, test_dir]:\n",
    "                os.makedirs(os.path.join(d, cleaned_name), exist_ok=True)\n",
    "            \n",
    "            src_path = os.path.join(SOURCE_DIR, class_name)\n",
    "            files = [f for f in os.listdir(src_path) if os.path.isfile(os.path.join(src_path, f))]\n",
    "            np.random.shuffle(files)\n",
    "            \n",
    "            train_split, val_split = 0.7, 0.15\n",
    "            train_end = int(len(files) * train_split)\n",
    "            val_end = train_end + int(len(files) * val_split)\n",
    "            \n",
    "            train_files, val_files, test_files = files[:train_end], files[train_end:val_end], files[val_end:]\n",
    "            \n",
    "            for f in train_files: shutil.copy(os.path.join(src_path, f), os.path.join(train_dir, cleaned_name, f))\n",
    "            for f in val_files: shutil.copy(os.path.join(src_path, f), os.path.join(val_dir, cleaned_name, f))\n",
    "            for f in test_files: shutil.copy(os.path.join(src_path, f), os.path.join(test_dir, cleaned_name, f))\n",
    "        print(\"Data splitting and directory setup complete.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Source directory not found at '{SOURCE_DIR}'. Please check the path.\")\n",
    "        \n",
    "# Run the setup\n",
    "setup_directories()\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "val_dir = os.path.join(BASE_DIR, 'val')\n",
    "test_dir = os.path.join(BASE_DIR, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 3. PRE-PROCESSING & VISUALIZATION FUNCTIONS ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Modular Custom Pre-processing Functions ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:38:16.790525Z",
     "iopub.status.busy": "2025-07-20T07:38:16.790346Z",
     "iopub.status.idle": "2025-07-20T07:38:16.796316Z",
     "shell.execute_reply": "2025-07-20T07:38:16.795551Z",
     "shell.execute_reply.started": "2025-07-20T07:38:16.790510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_clahe(image):\n",
    "    \"\"\"Applies Contrast Limited Adaptive Histogram Equalization (CLAHE).\"\"\"\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged_channels = cv2.merge([cl, a, b])\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2RGB)\n",
    "    return final_image\n",
    "\n",
    "def apply_gaussian_blur(image):\n",
    "    \"\"\"Applies a Gaussian blur to the image.\"\"\"\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "def get_preprocessing_function(model_specific_preprocess_input):\n",
    "    \"\"\"\n",
    "    Creates and returns a master preprocessing function that combines custom \n",
    "    steps with a model-specific one. This will be passed to ImageDataGenerator.\n",
    "    \"\"\"\n",
    "    def master_preprocessing_function(image):\n",
    "        # The input image from ImageDataGenerator is a float32 NumPy array [0, 255].\n",
    "        # Convert to uint8 for OpenCV operations.\n",
    "        processed_image = image.astype('uint8')\n",
    "        \n",
    "        # Apply custom pre-processing based on the switches\n",
    "        if APPLY_CLAHE:\n",
    "            processed_image = apply_clahe(processed_image)\n",
    "        if APPLY_GAUSSIAN_BLUR:\n",
    "            processed_image = apply_gaussian_blur(processed_image)\n",
    "            \n",
    "        # Convert back to float32 before passing to the model's required preprocessor\n",
    "        processed_image = processed_image.astype('float32')\n",
    "        # Apply the model-specific pre-processing (e.g., scaling, centering)\n",
    "        final_image = model_specific_preprocess_input(processed_image)\n",
    "        \n",
    "        return final_image\n",
    "        \n",
    "    return master_preprocessing_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Visualization Functions (No changes needed) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:38:16.797254Z",
     "iopub.status.busy": "2025-07-20T07:38:16.797041Z",
     "iopub.status.idle": "2025-07-20T07:38:16.821699Z",
     "shell.execute_reply": "2025-07-20T07:38:16.821168Z",
     "shell.execute_reply.started": "2025-07-20T07:38:16.797230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name, save_dir):\n",
    "    \"\"\"Plots and saves training & validation accuracy, loss, and precision.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0].set_title(f'{model_name} - Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[1].set_title(f'{model_name} - Loss')\n",
    "    axes[1].legend()\n",
    "    axes[2].plot(history.history['precision'], label='Train Precision')\n",
    "    axes[2].plot(history.history['val_precision'], label='Validation Precision')\n",
    "    axes[2].set_title(f'{model_name} - Precision')\n",
    "    axes[2].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_training_history.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name, save_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_confusion_matrix.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_pr_curves(y_true_bin, y_pred_prob, class_names, model_name, save_dir):\n",
    "    n_classes = len(class_names)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        axes[0].plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--'); axes[0].set_title(f'{model_name} - ROC Curve'); axes[0].legend()\n",
    "    precision, recall, pr_auc = {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "        pr_auc[i] = auc(recall[i], precision[i])\n",
    "        axes[1].plot(recall[i], precision[i], label=f'{class_names[i]} (AP = {pr_auc[i]:.2f})')\n",
    "    axes[1].set_title(f'{model_name} - Precision-Recall Curve'); axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_roc_pr_curves.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_projections(features, labels, class_names, model_name, save_dir):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)-1)).fit_transform(features)\n",
    "    df_tsne = pd.DataFrame({'x': tsne[:, 0], 'y': tsne[:, 1], 'label': [class_names[l] for l in labels]})\n",
    "    sns.scatterplot(data=df_tsne, x='x', y='y', hue='label', ax=axes[0], palette='viridis').set_title(f'{model_name} - t-SNE')\n",
    "    umap_proj = UMAP(n_neighbors=15, min_dist=0.1, random_state=42).fit_transform(features)\n",
    "    df_umap = pd.DataFrame({'x': umap_proj[:, 0], 'y': umap_proj[:, 1], 'label': [class_names[l] for l in labels]})\n",
    "    sns.scatterplot(data=df_umap, x='x', y='y', hue='label', ax=axes[1], palette='viridis').set_title(f'{model_name} - UMAP')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_projections.png'))\n",
    "    plt.show()\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path, alpha=0.4):\n",
    "    img = cv2.imread(img_path); img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])); heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = np.clip(heatmap * alpha + img, 0, 255).astype('uint8')\n",
    "    cv2.imwrite(cam_path, superimposed_img)\n",
    "\n",
    "def visualize_class_maps(model, last_conv_layer_name, model_specific_preprocess_input, model_name, save_dir):\n",
    "    class_names = sorted(os.listdir(test_dir))\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        img_path = os.path.join(test_dir, class_name, os.listdir(os.path.join(test_dir, class_name))[0])\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH)))\n",
    "        \n",
    "        # --- FIX: Replicate pre-processing manually and explicitly ---\n",
    "        # 1. Apply custom pre-processing\n",
    "        img_for_custom = img_array.copy().astype('uint8')\n",
    "        if APPLY_CLAHE:\n",
    "            img_for_custom = apply_clahe(img_for_custom)\n",
    "        if APPLY_GAUSSIAN_BLUR:\n",
    "            img_for_custom = apply_gaussian_blur(img_for_custom)\n",
    "            \n",
    "        # 2. Apply model-specific pre-processing\n",
    "        img_preprocessed = model_specific_preprocess_input(img_for_custom.astype('float32'))\n",
    "\n",
    "        # 3. Add batch dimension for model input\n",
    "        img_for_model = np.expand_dims(img_preprocessed, axis=0)\n",
    "        \n",
    "        heatmap = make_gradcam_heatmap(img_for_model, model, last_conv_layer_name)\n",
    "        cam_path = os.path.join(save_dir, f'{model_name}_gradcam_{class_name}.png')\n",
    "        save_and_display_gradcam(img_path, heatmap, cam_path)\n",
    "        ax = plt.subplot(2, 2, i + 1); ax.imshow(cv2.cvtColor(cv2.imread(cam_path), cv2.COLOR_BGR2RGB)); ax.set_title(f'Grad-CAM: {class_name}'); ax.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, save_dir, num_examples_per_class=2):\n",
    "    \"\"\"Visualizes model predictions on examples from each class, preventing text overlap.\"\"\"\n",
    "    filenames = test_generator.filenames\n",
    "    examples_shown = {name: 0 for name in class_names}\n",
    "    \n",
    "    total_images_to_plot = num_examples_per_class * len(class_names)\n",
    "    \n",
    "    # squeeze=False ensures `axes` is always a 2D array, preventing errors for single-row plots\n",
    "    fig, axes = plt.subplots(nrows=num_examples_per_class, ncols=len(class_names), \n",
    "                             figsize=(18, 5 * num_examples_per_class), squeeze=False)\n",
    "    fig.suptitle(f'{model_name} - Prediction Samples', fontsize=20)\n",
    "    \n",
    "    plotted_count = 0\n",
    "    for i in range(len(filenames)):\n",
    "        if plotted_count >= total_images_to_plot: break\n",
    "        \n",
    "        true_label_idx = y_true[i]\n",
    "        true_label_name = class_names[true_label_idx]\n",
    "\n",
    "        if examples_shown[true_label_name] < num_examples_per_class:\n",
    "            pred_label_idx = y_pred[i]\n",
    "            pred_label_name = class_names[pred_label_idx]\n",
    "            \n",
    "            img_path = os.path.join(test_dir, filenames[i])\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "            \n",
    "            # Get the correct subplot to draw on\n",
    "            row = examples_shown[true_label_name]\n",
    "            col = true_label_idx\n",
    "            ax = axes[row, col]\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            title_color = 'green' if pred_label_name == true_label_name else 'red'\n",
    "            ax.set_title(f\"True: {true_label_name}\\nPred: {pred_label_name}\", color=title_color, fontsize=12)\n",
    "            \n",
    "            examples_shown[true_label_name] += 1\n",
    "            plotted_count += 1\n",
    "    \n",
    "    # Hide any subplots that were not used\n",
    "    for ax in axes.flatten():\n",
    "        if not ax.images:\n",
    "            ax.axis('off')\n",
    "\n",
    "    # --- THE FIX ---\n",
    "    # Use fig.tight_layout() to automatically adjust subplot params so that subplots are nicely fit in the figure.\n",
    "    # The `h_pad` argument adds vertical padding between subplots to prevent titles from overlapping.\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96], h_pad=3.0)\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_prediction_samples.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T07:38:16.822511Z",
     "iopub.status.busy": "2025-07-20T07:38:16.822336Z",
     "iopub.status.idle": "2025-07-20T07:50:42.432949Z",
     "shell.execute_reply": "2025-07-20T07:50:42.431884Z",
     "shell.execute_reply.started": "2025-07-20T07:38:16.822496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 4. MAIN TRAINING & EVALUATION LOOP ---\n",
    "\n",
    "MODELS = {\n",
    "    'VGG16': (VGG16, tf.keras.applications.vgg16.preprocess_input),\n",
    "    'ResNet50': (ResNet50, tf.keras.applications.resnet50.preprocess_input),\n",
    "    'InceptionV3': (InceptionV3, tf.keras.applications.inception_v3.preprocess_input),\n",
    "    'Xception': (Xception, tf.keras.applications.xception.preprocess_input),\n",
    "    'MobileNetV2': (MobileNetV2, tf.keras.applications.mobilenet_v2.preprocess_input),\n",
    "    'DenseNet121': (DenseNet121, tf.keras.applications.densenet.preprocess_input),\n",
    "    'EfficientNetB0': (EfficientNetB0, tf.keras.applications.efficientnet.preprocess_input),\n",
    "}\n",
    "\n",
    "for model_name, (model_constructor, preprocess_input) in MODELS.items():\n",
    "    print(f\"\\n{'='*20} Training and Evaluating: {model_name} {'='*20}\")\n",
    "    \n",
    "    model_save_dir = os.path.join(OUTPUT_DIR, model_name)\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    # --- Get the combined pre-processing function for the current model ---\n",
    "    # This now includes your custom CLAHE/Blur steps\n",
    "    combined_preprocessor = get_preprocessing_function(preprocess_input)\n",
    "    \n",
    "    # --- Data Generators with combined pre-processing ---\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=combined_preprocessor,\n",
    "        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "        shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",
    "    )\n",
    "    val_test_datagen = ImageDataGenerator(preprocessing_function=combined_preprocessor)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "    validation_generator = val_test_datagen.flow_from_directory(val_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "    test_generator = val_test_datagen.flow_from_directory(test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "    \n",
    "    # --- Model Building ---\n",
    "    base_model = model_constructor(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D(name='feature_extractor_layer')(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # --- Compile & Train ---\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy', Precision(name='precision')])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=os.path.join(model_save_dir, f'{model_name}_best.keras'), save_best_only=True, monitor='val_accuracy')\n",
    "    ]\n",
    "    history = model.fit(train_generator, epochs=EPOCHS, validation_data=validation_generator, callbacks=callbacks)\n",
    "    \n",
    "    # --- Evaluation & Visualization ---\n",
    "    print(f\"\\n--- Generating visualizations for {model_name} ---\")\n",
    "    plot_training_history(history, model_name, model_save_dir)\n",
    "    \n",
    "    Y_pred_prob = model.predict(test_generator)\n",
    "    y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    print(f'\\nClassification Report for {model_name}:\\n{classification_report(y_true, y_pred, target_names=class_names)}')\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, model_name, model_save_dir)\n",
    "    y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
    "    plot_roc_pr_curves(y_true_bin, Y_pred_prob, class_names, model_name, model_save_dir)\n",
    "\n",
    "    feature_extractor = Model(inputs=model.input, outputs=model.get_layer('feature_extractor_layer').output)\n",
    "    test_features = feature_extractor.predict(test_generator)\n",
    "    plot_projections(test_features, y_true, class_names, model_name, model_save_dir)\n",
    "    \n",
    "    last_conv_layer_name = next((layer.name for layer in reversed(model.layers) if isinstance(layer, tf.keras.layers.Conv2D)), None)\n",
    "    if last_conv_layer_name:\n",
    "        visualize_class_maps(model, last_conv_layer_name, combined_preprocessor, model_name, model_save_dir)\n",
    "    \n",
    "    print(f\"\\nFinished processing {model_name}. Results saved to {model_save_dir}\")\n",
    "    visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, model_save_dir)\n",
    "    \n",
    "    print(f\"\\nFinished processing {model_name}. Results saved to {model_save_dir}\")\n",
    "\n",
    "print(\"\\nAll models have been trained and evaluated.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3771148,
     "sourceId": 6523161,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
