{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:18:45.778306Z","iopub.execute_input":"2025-07-26T05:18:45.778642Z","iopub.status.idle":"2025-07-26T05:18:45.787438Z","shell.execute_reply.started":"2025-07-26T05:18:45.778616Z","shell.execute_reply":"2025-07-26T05:18:45.786310Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom scipy.signal import wiener\n\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.manifold import TSNE\nfrom umap import UMAP\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.applications import (\n    VGG16, VGG19, ResNet50, InceptionV3, Xception, MobileNetV2, \n    DenseNet121, EfficientNetB0, InceptionResNetV2\n)\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Average\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.metrics import Precision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:18:45.789103Z","iopub.execute_input":"2025-07-26T05:18:45.789959Z","iopub.status.idle":"2025-07-26T05:19:31.274975Z","shell.execute_reply.started":"2025-07-26T05:18:45.789608Z","shell.execute_reply":"2025-07-26T05:19:31.273965Z"}},"outputs":[{"name":"stderr","text":"2025-07-26 05:18:49.288355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753507129.524120      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753507129.598176      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# --- 1. CONFIGURATION AND SETUP ---","metadata":{}},{"cell_type":"markdown","source":"# --- Dataset and Output Paths ---","metadata":{}},{"cell_type":"code","source":"SOURCE_DIR = '/kaggle/input/plantvillage-dataset/color'\nBASE_DIR = '/kaggle/working/crop_dataset_split'\nOUTPUT_DIR = '/kaggle/working/model_outputs' # Directory to save all results\nData_Selector = ['Peach___', 'Pepper,_bell___', 'Strawberry___']\n\nCLASS_MAP = {\n    'Peach___': 'peach',\n    'Pepper,_bell___': 'bell_pepper',\n    'Strawberry___': 'strawberry'\n    # Add other classes here following the same pattern\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:19:31.275803Z","iopub.execute_input":"2025-07-26T05:19:31.276740Z","iopub.status.idle":"2025-07-26T05:19:31.282615Z","shell.execute_reply.started":"2025-07-26T05:19:31.276702Z","shell.execute_reply":"2025-07-26T05:19:31.281365Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# --- Model and Training Parameters ---","metadata":{}},{"cell_type":"code","source":"IMG_HEIGHT = 224\nIMG_WIDTH = 224\nBATCH_SIZE = 32\nNUM_CLASSES = 6 \nEPOCHS = 30\nEARLY_STOPPING_PATIENCE = 10\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:19:31.283786Z","iopub.execute_input":"2025-07-26T05:19:31.284086Z","iopub.status.idle":"2025-07-26T05:19:31.344286Z","shell.execute_reply.started":"2025-07-26T05:19:31.284061Z","shell.execute_reply":"2025-07-26T05:19:31.343154Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# --- Preprocessing Toggles ---","metadata":{}},{"cell_type":"code","source":"APPLY_CLAHE = False\nAPPLY_GAUSSIAN_BLUR = False \nAPPLY_MEDIAN_FILTER = False\nAPPLY_WIENER_FILTER = False\nAPPLY_HISTOGRAM_EQUALIZATION = False\nAPPLY_LAPLACIAN_FILTER = False\nAPPLY_AVERAGE_FILTER = False\nAPPLY_SOBEL_FILTER = False\nAPPLY_CANNY_FILTER = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:19:31.346067Z","iopub.execute_input":"2025-07-26T05:19:31.346682Z","iopub.status.idle":"2025-07-26T05:19:31.363177Z","shell.execute_reply.started":"2025-07-26T05:19:31.346653Z","shell.execute_reply":"2025-07-26T05:19:31.362165Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def setup_directories():\n    \n    if os.path.exists(BASE_DIR):\n        print(f\"Directory '{BASE_DIR}' already exists. Deleting it to recreate...\")\n        shutil.rmtree(BASE_DIR)\n    \n    print(\"Creating new train/val/test directories...\")\n    train_dir = os.path.join(BASE_DIR, 'train')\n    val_dir = os.path.join(BASE_DIR, 'val')\n    test_dir = os.path.join(BASE_DIR, 'test')\n    \n    os.makedirs(train_dir)\n    os.makedirs(val_dir)\n    os.makedirs(test_dir)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    try:\n        # Filter for directories that start with one of the prefixes from our map\n        class_names = [\n            d for d in os.listdir(SOURCE_DIR)\n            if os.path.isdir(os.path.join(SOURCE_DIR, d)) and d.startswith(tuple(CLASS_MAP.keys()))\n        ]\n        \n        if not class_names:\n            print(f\"ERROR: No matching class directories found in '{SOURCE_DIR}'.\")\n            print(f\"Searched for directories starting with: {list(CLASS_MAP.keys())}\")\n            return\n\n        print(f\"Found {len(class_names)} matching class directories to process.\")\n\n        for class_name in class_names:\n            print(f\"Processing '{class_name}'...\")\n            \n            # --- CHANGE 2: New name cleaning logic using the CLASS_MAP ---\n            cleaned_name = class_name\n            for prefix, clean_crop_name in CLASS_MAP.items():\n                if class_name.startswith(prefix):\n                    # Get the part after the prefix (e.g., 'healthy', 'Bacterial_spot')\n                    status = class_name.replace(prefix, '', 1)\n                    # Clean the status: replace underscores with spaces and make it lowercase\n                    cleaned_status = status.replace('_', ' ').lower()\n                    # Combine the clean crop name and the status\n                    cleaned_name = f\"{clean_crop_name} {cleaned_status}\"\n                    break\n            \n            print(f\"  -> Cleaned name will be: '{cleaned_name}'\")\n\n            # Create subdirectories using the new cleaned name\n            for d in [train_dir, val_dir, test_dir]:\n                os.makedirs(os.path.join(d, cleaned_name), exist_ok=True)\n            \n            # Get all file paths from the source class directory\n            src_path = os.path.join(SOURCE_DIR, class_name)\n            files = [f for f in os.listdir(src_path) if os.path.isfile(os.path.join(src_path, f))]\n            \n            np.random.shuffle(files)\n            \n            # Split files into train/val/test sets\n            train_split, val_split = 0.7, 0.15\n            train_end = int(len(files) * train_split)\n            val_end = train_end + int(len(files) * val_split)\n            train_files, val_files, test_files = files[:train_end], files[train_end:val_end], files[val_end:]\n            \n            # Copy files into the correctly named directories\n            for f in train_files:\n                shutil.copy(os.path.join(src_path, f), os.path.join(train_dir, cleaned_name, f))\n            for f in val_files:\n                shutil.copy(os.path.join(src_path, f), os.path.join(val_dir, cleaned_name, f))\n            for f in test_files:\n                shutil.copy(os.path.join(src_path, f), os.path.join(test_dir, cleaned_name, f))\n\n        print(\"\\nData splitting and directory setup complete.\")\n        print(f\"Dataset created at: '{BASE_DIR}'\")\n\n    except FileNotFoundError:\n        print(f\"ERROR: Source directory not found at '{SOURCE_DIR}'. Please check the path.\")\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n\n# --- Run the Setup ---\nsetup_directories()\n\n# You can now use these variables to point to your new dataset\ntrain_dir = os.path.join(BASE_DIR, 'train')\nval_dir = os.path.join(BASE_DIR, 'val')\ntest_dir = os.path.join(BASE_DIR, 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T05:19:31.364261Z","iopub.execute_input":"2025-07-26T05:19:31.364512Z","iopub.status.idle":"2025-07-26T05:20:27.170124Z","shell.execute_reply.started":"2025-07-26T05:19:31.364490Z","shell.execute_reply":"2025-07-26T05:20:27.169167Z"}},"outputs":[{"name":"stdout","text":"Creating new train/val/test directories...\nFound 6 matching class directories to process.\nProcessing 'Strawberry___Leaf_scorch'...\n  -> Cleaned name will be: 'strawberry leaf scorch'\nProcessing 'Peach___healthy'...\n  -> Cleaned name will be: 'peach healthy'\nProcessing 'Peach___Bacterial_spot'...\n  -> Cleaned name will be: 'peach bacterial spot'\nProcessing 'Pepper,_bell___healthy'...\n  -> Cleaned name will be: 'bell_pepper healthy'\nProcessing 'Strawberry___healthy'...\n  -> Cleaned name will be: 'strawberry healthy'\nProcessing 'Pepper,_bell___Bacterial_spot'...\n  -> Cleaned name will be: 'bell_pepper bacterial spot'\n\nData splitting and directory setup complete.\nDataset created at: '/kaggle/working/crop_dataset_split'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# --- 2. PREPROCESSING FUNCTIONS ---","metadata":{}},{"cell_type":"code","source":"def apply_clahe(image):\n    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab_image)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    cl = clahe.apply(l)\n    merged_channels = cv2.merge([cl, a, b])\n    return cv2.cvtColor(merged_channels, cv2.COLOR_LAB2RGB)\n\ndef apply_gaussian_blur(image):\n    return cv2.GaussianBlur(image, (5, 5), 0)\n\ndef apply_median_blur(image):\n    return cv2.medianBlur(image, 5)\n\ndef apply_wiener_filter(image):\n    img_float = image.astype(np.float64) / 255.0\n    filtered_channels = [wiener(channel) for channel in cv2.split(img_float)]\n    filtered_image = cv2.merge(filtered_channels)\n    return (np.clip(filtered_image, 0, 1) * 255).astype(np.uint8)\n\ndef apply_histogram_equalization(image):\n    img_ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n    img_ycrcb[:, :, 0] = cv2.equalizeHist(img_ycrcb[:, :, 0])\n    return cv2.cvtColor(img_ycrcb, cv2.COLOR_YCrCb2RGB)\n\ndef apply_laplacian_filter(image):\n    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n    abs_laplacian = np.absolute(laplacian)\n    return np.uint8(abs_laplacian)\n\ndef apply_average_filter(image):\n    return cv2.blur(image, (5, 5))\n\ndef apply_sobel_filter(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n    sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n    sobel_norm = cv2.normalize(sobel_combined, None, 0, 255, cv2.NORM_MINMAX)\n    sobel_uint8 = np.uint8(sobel_norm)\n    return cv2.cvtColor(sobel_uint8, cv2.COLOR_GRAY2RGB)\n\ndef apply_canny_filter(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    edges = cv2.Canny(gray, threshold1=100, threshold2=200)\n    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n\ndef get_preprocessing_function(model_specific_preprocess_input):\n    def master_preprocessing_function(image):\n        if model_specific_preprocess_input is None:\n            return image / 255.0\n            \n        processed_image = image.astype('uint8')\n        if APPLY_WIENER_FILTER: processed_image = apply_wiener_filter(processed_image)\n        if APPLY_MEDIAN_FILTER: processed_image = apply_median_blur(processed_image)\n        if APPLY_AVERAGE_FILTER: processed_image = apply_average_filter(processed_image)\n        if APPLY_GAUSSIAN_BLUR: processed_image = apply_gaussian_blur(processed_image)\n        if APPLY_CLAHE: processed_image = apply_clahe(processed_image)\n        if APPLY_HISTOGRAM_EQUALIZATION: processed_image = apply_histogram_equalization(processed_image)\n        if APPLY_LAPLACIAN_FILTER: processed_image = apply_laplacian_filter(processed_image)\n        if APPLY_SOBEL_FILTER: processed_image = apply_sobel_filter(processed_image)\n        if APPLY_CANNY_FILTER: processed_image = apply_canny_filter(processed_image)\n        processed_image = processed_image.astype('float32')\n        return model_specific_preprocess_input(processed_image)\n    return master_preprocessing_function","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:38:43.291258Z","iopub.execute_input":"2025-07-22T05:38:43.291574Z","iopub.status.idle":"2025-07-22T05:38:43.301837Z","shell.execute_reply.started":"2025-07-22T05:38:43.291557Z","shell.execute_reply":"2025-07-22T05:38:43.301157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Function to Create the Custom CNN Model ---","metadata":{}},{"cell_type":"code","source":"def create_custom_cnn(input_shape, num_classes):\n    \"\"\"Builds and returns the user-defined custom CNN model.\"\"\"\n    model = keras.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Conv2D(16, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(32, (1, 1), activation='relu'),\n        layers.Conv2D(32, (3, 3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(64, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (5, 5), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(3, 3),\n        layers.Conv2D(16, (1, 1), activation='relu'),\n        layers.BatchNormalization(),\n        layers.Conv2D(16, (5, 5), activation='relu'),\n        layers.BatchNormalization(),\n        # Add a feature extractor layer name for Grad-CAM and feature projection\n        layers.GlobalAveragePooling2D(name='feature_extractor_layer'),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    print(\"--- Custom CNN Model Summary ---\")\n    model.summary()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:38:43.302546Z","iopub.execute_input":"2025-07-22T05:38:43.302887Z","iopub.status.idle":"2025-07-22T05:38:43.341371Z","shell.execute_reply.started":"2025-07-22T05:38:43.302858Z","shell.execute_reply":"2025-07-22T05:38:43.340870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 3. VISUALIZATION AND REPORTING FUNCTIONS ---","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history, model_name, save_dir):\n    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n    axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n    axes[0].set_title(f'{model_name} - Accuracy'); axes[0].legend()\n    axes[1].plot(history.history['loss'], label='Train Loss')\n    axes[1].plot(history.history['val_loss'], label='Validation Loss')\n    axes[1].set_title(f'{model_name} - Loss'); axes[1].legend()\n    axes[2].plot(history.history['precision'], label='Train Precision')\n    axes[2].plot(history.history['val_precision'], label='Validation Precision')\n    axes[2].set_title(f'{model_name} - Precision'); axes[2].legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_training_history.png'))\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, model_name, save_dir):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'{model_name} - Confusion Matrix')\n    plt.savefig(os.path.join(save_dir, f'{model_name}_confusion_matrix.png'))\n    plt.show()\n\ndef plot_roc_pr_curves(y_true_bin, y_pred_prob, class_names, model_name, save_dir):\n    n_classes = len(class_names)\n    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n    fpr, tpr, roc_auc = {}, {}, {}\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n        axes[0].plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n    axes[0].plot([0, 1], [0, 1], 'k--'); axes[0].set_title(f'{model_name} - ROC Curve'); axes[0].legend()\n    precision, recall, pr_auc = {}, {}, {}\n    for i in range(n_classes):\n        precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n        pr_auc[i] = auc(recall[i], precision[i])\n        axes[1].plot(recall[i], precision[i], label=f'{class_names[i]} (AP = {pr_auc[i]:.2f})')\n    axes[1].set_title(f'{model_name} - Precision-Recall Curve'); axes[1].legend()\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_roc_pr_curves.png'))\n    plt.show()\n\ndef plot_projections(features, labels, class_names, model_name, save_dir):\n    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)-1)).fit_transform(features)\n    df_tsne = pd.DataFrame({'x': tsne[:, 0], 'y': tsne[:, 1], 'label': [class_names[l] for l in labels]})\n    sns.scatterplot(data=df_tsne, x='x', y='y', hue='label', ax=axes[0], palette='viridis').set_title(f'{model_name} - t-SNE')\n    umap_proj = UMAP(n_neighbors=15, min_dist=0.1, random_state=42).fit_transform(features)\n    df_umap = pd.DataFrame({'x': umap_proj[:, 0], 'y': umap_proj[:, 1], 'label': [class_names[l] for l in labels]})\n    sns.scatterplot(data=df_umap, x='x', y='y', hue='label', ax=axes[1], palette='viridis').set_title(f'{model_name} - UMAP')\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f'{model_name}_projections.png'))\n    plt.show()\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef save_and_display_gradcam(img_path, heatmap, cam_path, alpha=0.4):\n    img = cv2.imread(img_path); img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])); heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = np.clip(heatmap * alpha + img, 0, 255).astype('uint8')\n    cv2.imwrite(cam_path, superimposed_img)\n\n\ndef visualize_class_maps(model, last_conv_layer_name, master_preprocessor, model_name, save_dir):\n    class_names = sorted(os.listdir(test_dir))\n    plt.figure(figsize=(15, 10))\n    for i, class_name in enumerate(class_names):\n        img_path = os.path.join(test_dir, class_name, os.listdir(os.path.join(test_dir, class_name))[0])\n        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n        img_array = img_to_array(img)\n        img_preprocessed = master_preprocessor(img_array.copy())\n        img_for_model = np.expand_dims(img_preprocessed, axis=0)\n        heatmap = make_gradcam_heatmap(img_for_model, model, last_conv_layer_name)\n        cam_path = os.path.join(save_dir, f'{model_name}_gradcam_{class_name}.png')\n        save_and_display_gradcam(img_path, heatmap, cam_path)\n        ax = plt.subplot(2, 2, i + 1); ax.imshow(cv2.cvtColor(cv2.imread(cam_path), cv2.COLOR_BGR2RGB)); ax.set_title(f'Grad-CAM: {class_name}'); ax.axis(\"off\")\n    plt.tight_layout(); plt.show()\n\n\n\ndef visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, save_dir, num_examples_per_class=2):\n    filenames = test_generator.filenames\n    examples_shown = {name: 0 for name in class_names}\n    total_images_to_plot = num_examples_per_class * len(class_names)\n    fig, axes = plt.subplots(nrows=num_examples_per_class, ncols=len(class_names), figsize=(18, 5 * num_examples_per_class), squeeze=False)\n    fig.suptitle(f'{model_name} - Prediction Samples', fontsize=20)\n    plotted_count = 0\n    for i in range(len(filenames)):\n        if plotted_count >= total_images_to_plot: break\n        true_label_idx = y_true[i]\n        true_label_name = class_names[true_label_idx]\n        if examples_shown[true_label_name] < num_examples_per_class:\n            pred_label_idx = y_pred[i]\n            pred_label_name = class_names[pred_label_idx]\n            img_path = os.path.join(test_dir, filenames[i])\n            img = load_img(img_path)\n            row = examples_shown[true_label_name]\n            col = true_label_idx\n            ax = axes[row, col]\n            ax.imshow(img)\n            ax.axis('off')\n            title_color = 'green' if pred_label_name == true_label_name else 'red'\n            ax.set_title(f\"True: {true_label_name}\\nPred: {pred_label_name}\", color=title_color, fontsize=12)\n            examples_shown[true_label_name] += 1\n            plotted_count += 1\n    for ax in axes.flatten():\n        if not ax.images:\n            ax.axis('off')\n    fig.tight_layout(rect=[0, 0, 1, 0.96], h_pad=5.0)\n    plt.savefig(os.path.join(save_dir, f'{model_name}_prediction_samples.png'))\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:38:43.342011Z","iopub.execute_input":"2025-07-22T05:38:43.342172Z","iopub.status.idle":"2025-07-22T05:38:43.371102Z","shell.execute_reply.started":"2025-07-22T05:38:43.342159Z","shell.execute_reply":"2025-07-22T05:38:43.370596Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- 4. MAIN TRAINING & EVALUATION LOOP ---","metadata":{}},{"cell_type":"code","source":"# --- Model Registry ---\nMODELS = {\n    'CustomCNN': (None, None),\n    'VGG16': (VGG16, tf.keras.applications.vgg16.preprocess_input),\n    'VGG19': (VGG19, tf.keras.applications.vgg19.preprocess_input),\n    'ResNet50': (ResNet50, tf.keras.applications.resnet50.preprocess_input),\n    'InceptionV3': (InceptionV3, tf.keras.applications.inception_v3.preprocess_input),\n    'Xception': (Xception, tf.keras.applications.xception.preprocess_input),\n    'MobileNetV2': (MobileNetV2, tf.keras.applications.mobilenet_v2.preprocess_input),\n    'DenseNet121': (DenseNet121, tf.keras.applications.densenet.preprocess_input),\n    'EfficientNetB0': (EfficientNetB0, tf.keras.applications.efficientnet.preprocess_input),\n    'InceptionResNetV2': (InceptionResNetV2, tf.keras.applications.inception_resnet_v2.preprocess_input),\n}\n\n# --- Main Training and Evaluation Loop ---\nfor model_name, (model_constructor, preprocess_input) in MODELS.items():\n    print(f\"\\n{'='*20} Training and Evaluating: {model_name} {'='*20}\")\n    model_save_dir = os.path.join(OUTPUT_DIR, model_name)\n    os.makedirs(model_save_dir, exist_ok=True)\n    \n    master_preprocessor = get_preprocessing_function(preprocess_input)\n    \n    # --- Data Generators ---\n    if model_name == 'CustomCNN':\n         train_datagen = ImageDataGenerator(rescale=1./255)\n         val_test_datagen = ImageDataGenerator(rescale=1./255)\n    else:\n        train_datagen = ImageDataGenerator(\n            preprocessing_function=master_preprocessor,\n            rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n            shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n        )\n        val_test_datagen = ImageDataGenerator(preprocessing_function=master_preprocessor)\n\n    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')\n    validation_generator = val_test_datagen.flow_from_directory(val_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')\n    test_generator = val_test_datagen.flow_from_directory(test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n    \n    # --- Model Building ---\n    if model_name == 'CustomCNN':\n        model = create_custom_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=NUM_CLASSES)\n    else:\n        base_model = model_constructor(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n        base_model.trainable = False\n        x = GlobalAveragePooling2D(name='feature_extractor_layer')(base_model.output)\n        x = Dense(128, activation='relu')(x)\n        x = Dropout(0.5)(x)\n        predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n        model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # --- Model Training ---\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy', Precision(name='precision')])\n    best_model_path = os.path.join(model_save_dir, f'{model_name}_best.keras')\n    callbacks = [\n        EarlyStopping(monitor='val_accuracy', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True),\n        ModelCheckpoint(filepath=best_model_path, save_best_only=True, monitor='val_accuracy')\n    ]\n    history = model.fit(train_generator, epochs=EPOCHS, validation_data=validation_generator, callbacks=callbacks)\n    \n    # --- Evaluation & Visualization ---\n    print(f\"\\n--- Loading best model from '{best_model_path}' for evaluation ---\")\n    model = tf.keras.models.load_model(best_model_path)\n    \n    print(f\"\\n--- Generating visualizations for {model_name} ---\")\n    plot_training_history(history, model_name, model_save_dir)\n    \n    Y_pred_prob = model.predict(test_generator)\n    y_pred = np.argmax(Y_pred_prob, axis=1)\n    y_true = test_generator.classes\n    class_names = list(test_generator.class_indices.keys())\n    \n    print(f'\\nClassification Report for {model_name}:\\n{classification_report(y_true, y_pred, target_names=class_names)}')\n    plot_confusion_matrix(y_true, y_pred, class_names, model_name, model_save_dir)\n    y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n    plot_roc_pr_curves(y_true_bin, Y_pred_prob, class_names, model_name, model_save_dir)\n    \n    # --- Feature Projection Visualization ---\n    if model_name == 'CustomCNN':\n        extractor_layer_index = next(i for i, layer in enumerate(model.layers) if layer.name == 'feature_extractor_layer')\n        feature_extractor = tf.keras.Sequential(model.layers[:extractor_layer_index + 1])\n    else:\n        feature_extractor = Model(inputs=model.inputs, outputs=model.get_layer('feature_extractor_layer').output)\n    \n    test_features = feature_extractor.predict(test_generator)\n    plot_projections(test_features, y_true, class_names, model_name, model_save_dir)\n    \n    \n    # --- Grad-CAM and Prediction Visualization ---\n    last_conv_layer_name = next((layer.name for layer in reversed(model.layers) if 'conv' in layer.name.lower()), None)\n    \n    if last_conv_layer_name and model_name != 'CustomCNN':\n        print(f\"Generating Grad-CAM maps for {model_name} using layer: {last_conv_layer_name}\")\n        # Assuming the general-purpose make_gradcam_heatmap and visualize_class_maps are defined\n        visualize_class_maps(model, last_conv_layer_name, master_preprocessor, model_name, model_save_dir)\n    else:\n        print(f\"Could not find a convolutional layer for Grad-CAM in {model_name}. Skipping.\")\n\n    visualize_predictions(y_true, y_pred, test_generator, class_names, model_name, model_save_dir)\n\n    print(f\"\\nFinished processing {model_name}. Results saved to {model_save_dir}\")\n\nprint(\"\\nAll individual models have been trained and evaluated.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:38:43.371774Z","iopub.execute_input":"2025-07-22T05:38:43.371990Z","iopub.status.idle":"2025-07-22T05:55:21.870705Z","shell.execute_reply.started":"2025-07-22T05:38:43.371967Z","shell.execute_reply":"2025-07-22T05:55:21.869750Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # --- Evaluation & Visualization ---","metadata":{}},{"cell_type":"code","source":"def evaluate_ensemble(ensemble_model_names, ensemble_name):\n    \"\"\"\n    Loads a list of models, averages their predictions, and evaluates the resulting ensemble.\n    \"\"\"\n    print(f\"\\n{'='*20} Creating and Evaluating Ensemble: {ensemble_name} {'='*20}\")\n    \n    all_preds = []\n    y_true_ensemble = None\n    class_names_ensemble = None\n\n    for model_name in ensemble_model_names:\n        print(f\"--- Loading model: {model_name} for ensembling ---\")\n        \n        _ , preprocess_input = MODELS.get(model_name)\n        \n        model_path = os.path.join(OUTPUT_DIR, model_name, f'{model_name}_best.keras')\n        if not os.path.exists(model_path):\n            print(f\"Warning: Model file not found for {model_name} at {model_path}. Skipping.\")\n            continue\n        \n        model = tf.keras.models.load_model(model_path)\n        \n        master_preprocessor = get_preprocessing_function(preprocess_input)\n        \n        if model_name == 'CustomCNN':\n             test_datagen = ImageDataGenerator(rescale=1./255)\n        else:\n             test_datagen = ImageDataGenerator(preprocessing_function=master_preprocessor)\n\n        test_generator_ensemble = test_datagen.flow_from_directory(\n            test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE,\n            class_mode='categorical', shuffle=False\n        )\n        \n        if y_true_ensemble is None:\n            y_true_ensemble = test_generator_ensemble.classes\n            class_names_ensemble = list(test_generator_ensemble.class_indices.keys())\n            \n        preds = model.predict(test_generator_ensemble)\n        all_preds.append(preds)\n\n    if len(all_preds) < 2:\n        print(f\"Could not create ensemble '{ensemble_name}' because fewer than 2 valid models were found.\")\n        return\n\n    print(f\"\\n--- Averaging predictions for '{ensemble_name}' ---\")\n    ensemble_preds_prob = np.mean(all_preds, axis=0)\n    ensemble_y_pred = np.argmax(ensemble_preds_prob, axis=1)\n\n    ensemble_save_dir = os.path.join(OUTPUT_DIR, ensemble_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\"))\n    os.makedirs(ensemble_save_dir, exist_ok=True)\n\n    print(f'\\nClassification Report for {ensemble_name}:\\n{classification_report(y_true_ensemble, ensemble_y_pred, target_names=class_names_ensemble)}')\n    plot_confusion_matrix(y_true_ensemble, ensemble_y_pred, class_names_ensemble, ensemble_name, ensemble_save_dir)\n    y_true_bin_ensemble = label_binarize(y_true_ensemble, classes=range(NUM_CLASSES))\n    plot_roc_pr_curves(y_true_bin_ensemble, ensemble_preds_prob, class_names_ensemble, ensemble_name, ensemble_save_dir)\n    print(f\"\\nFinished processing {ensemble_name}. Results saved to {ensemble_save_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:55:21.871556Z","iopub.execute_input":"2025-07-22T05:55:21.871818Z","iopub.status.idle":"2025-07-22T05:55:21.885237Z","shell.execute_reply.started":"2025-07-22T05:55:21.871801Z","shell.execute_reply":"2025-07-22T05:55:21.884525Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --- Define and run hard-coded ensembles ---","metadata":{}},{"cell_type":"code","source":"# Ensemble of 2 models\nevaluate_ensemble(['VGG16', 'EfficientNetB0'], \"Ensemble of 2 (VGG16, EfficientNetB0)\")\nevaluate_ensemble(['VGG19', 'EfficientNetB0'], \"Ensemble of 2 (VGG19, EfficientNetB0)\")\nevaluate_ensemble(['ResNet50', 'EfficientNetB0'], \"Ensemble of 2 (ResNet50, EfficientNetB0)\")\nevaluate_ensemble(['MobileNetV2', 'EfficientNetB0'], \"Ensemble of 2 (MobileNetV2, EfficientNetB0)\")\nevaluate_ensemble(['ResNet50', 'MobileNetV2'], \"Ensemble of 2 (ResNet50, MobileNetV2)\")\nevaluate_ensemble(['Xception', 'MobileNetV2'], \"Ensemble of 2 (Xception, MobileNetV2)\")\nevaluate_ensemble(['EfficientNetB0', 'Xception'], \"Ensemble of 2 (EfficientNetB0, Xception)\")\nevaluate_ensemble(['DenseNet121', 'EfficientNetB0'], \"Ensemble of 2 (DenseNet121, EfficientNetB0)\")\n\n# Ensemble of 3 models\nevaluate_ensemble(['VGG19', 'EfficientNetB0', 'InceptionV3'], \"Ensemble of 3 (VGG19, EfficientNetB0, InceptionV3)\")\nevaluate_ensemble(['MobileNetV2', 'EfficientNetB0', 'InceptionV3'], \"Ensemble of 3 (MobileNetV2, EfficientNetB0, InceptionV3)\")\nevaluate_ensemble(['DenseNet121', 'EfficientNetB0', 'MobileNetV2'], \"Ensemble of 3 (DenseNet121, EfficientNetB0, MobileNetV2)\")\nevaluate_ensemble(['EfficientNetB0', 'VGG19', 'MobileNetV2'], \"Ensemble of 3 (EfficientNetB0, VGG19, MobileNetV2)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:55:21.886020Z","iopub.execute_input":"2025-07-22T05:55:21.886293Z"}},"outputs":[],"execution_count":null}]}